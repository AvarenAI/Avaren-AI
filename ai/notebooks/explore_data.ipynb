{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization Notebook\n",
    "\n",
    "This notebook is designed for exploring and visualizing datasets to gain insights before training AI models. It includes steps for data loading, cleaning, statistical analysis, and visualization using various Python libraries. The goal is to understand the structure, patterns, and potential issues in the data.\n",
    "\n",
    "**Note**: Replace the dataset path with your own data file (e.g., CSV, JSON) or use a sample dataset as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing the necessary libraries for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\n",
    "\n",
    "Load the dataset into a Pandas DataFrame. For this example, we'll use a sample dataset. Replace the path or dataset as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample dataset (replace with your own dataset path)\n",
    "try:\n",
    "    # Example: Using a publicly available dataset or local file\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    # Fallback to a smaller built-in dataset if needed\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "    print(\"Fallback dataset loaded successfully!\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Inspection\n",
    "\n",
    "Let's inspect the dataset to understand its structure, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nDataset Description:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check for Missing Values\n",
    "\n",
    "Identify and visualize missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualize missing values using a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Distribution Analysis\n",
    "\n",
    "Visualize the distribution of numerical columns to understand their spread and potential skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# Check skewness and kurtosis\n",
    "for col in numerical_cols:\n",
    "    skewness = stats.skew(df[col])\n",
    "    kurtosis = stats.kurtosis(df[col])\n",
    "    print(f\"{col} - Skewness: {skewness:.2f}, Kurtosis: {kurtosis:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Data Analysis\n",
    "\n",
    "Analyze and visualize categorical columns to understand their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Plot count plots for categorical columns\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.title(f'Count Plot of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Display value counts\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nValue Counts for {col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Explore relationships between numerical variables using correlation matrices and heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pairwise Relationships\n",
    "\n",
    "Visualize pairwise relationships between variables using scatter plots and pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for numerical columns (limit to first 5 for performance)\n",
    "sns.pairplot(df[numerical_cols[:5]])\n",
    "plt.suptitle('Pairwise Relationships', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Outlier Detection\n",
    "\n",
    "Identify potential outliers in numerical columns using box plots and IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot box plots for numerical columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=df, y=col)\n",
    "    plt.title(f'Box Plot of {col} for Outlier Detection')\n",
    "    plt.show()\n",
    "\n",
    "# Calculate IQR and detect outliers\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    print(f\"\\nOutliers in {col}:\")\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Visualizations with Plotly\n",
    "\n",
    "Create interactive plots for deeper exploration using Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter plot (adjust columns as needed)\n",
    "if len(numerical_cols) >= 2:\n",
    "    fig = px.scatter(df, x=numerical_cols[0], y=numerical_cols[1], color=df.columns[-1] if 'target' in df.columns or len(categorical_cols) > 0 else None,\n",
    "                     title='Interactive Scatter Plot')\n",
    "    fig.show()\n",
    "\n",
    "# Interactive box plot\n",
    "if len(numerical_cols) > 0:\n",
    "    fig = px.box(df, y=numerical_cols[0], title=f'Interactive Box Plot of {numerical_cols[0]}')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Insights\n",
    "\n",
    "Summarize key findings from the exploration and note any actions needed for data preprocessing or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of key insights\n",
    "print(\"Key Insights from Data Exploration:\")\n",
    "print(\"1. Dataset Shape:\", df.shape)\n",
    "print(\"2. Missing Values:\", df.isnull().sum().sum())\n",
    "print(\"3. Numerical Columns:\", list(numerical_cols))\n",
    "print(\"4. Categorical Columns:\", list(categorical_cols))\n",
    "print(\"5. Potential Issues: Check for outliers and skewed distributions as shown in plots.\")\n",
    "print(\"6. Next Steps: Handle missing values, encode categorical variables, and normalize numerical features if needed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
